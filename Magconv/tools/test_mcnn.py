import torch
import numpy as np
import utlis.logging as logging
import utlis.misc as misc
import utlis.checkpoint as cu
import datasets.loader as loader
from utlis.meters import TestMeter
import utlis.metrics as metrics
from models.build import build_model

logger = logging.get_logger(__name__)

@torch.no_grad()
def perform_test(test_loader, model, test_meter, cfg):
    """
    Evaluate the model on the testing set.
    Args:
        test_loader (loader): data loader to provide testing data.
        model (model): model to evaluate the performance.
        test_meter (TestMeter): meter instance to record and calculate the metrics.
        cfg (CfgNode): configs. 
    """

    # Evaluation mode enabled. The running stats would not be updated.
    model.eval()
    cur_device = next(model.parameters()).device

    for cur_iter, (mag_data, label) in enumerate(test_loader):
        mag_data = mag_data.permute(0,2,1)

        # Transfer the data to the current GPU device.
        if cfg.GPU_ENABLE:
            mag_data = mag_data.to(cur_device, non_blocking=True)       #[bsz, 3, len]
            label = label.to(cur_device, non_blocking=True)             #[bsz]
                
        preds = model(mag_data)                         #[bsz,1]
        preds = torch.floor(torch.exp(preds))

        bsz = mag_data.size(0)
        l1_err = metrics.l1_error(preds, label.unsqueeze(-1))

        # Copy the stats from GPU to CPU (sync point).
        l1_err = l1_err.item()
                                
        
        # Update and log stats.
        test_meter.update_stats(
            l1_err,
            bsz,
        )
        test_meter.log_iter_stats(cur_iter)
        test_meter.update_predictions(mag_data, preds, label.unsqueeze(-1))

    #Save preds.
    test_meter.save_predictions()

    # Log stats.
    test_meter.log_stats()
    
    test_meter.reset()

def test(cfg):
    """
    Args:
        cfg (CfgNode): configs. 
    """
    # Set random seed from configs.
    np.random.seed(cfg.RNG_SEED)
    torch.manual_seed(cfg.RNG_SEED)
    torch.backends.cudnn.deterministic = True


    # Setup logging format.
    logging.setup_logging(cfg.OUTPUT_DIR)

    # Print config.
    logger.info("Test Magnetic CNN with config:")
    logger.info(cfg)

    # Build the magnetic calibration model and print model statistics.
    model = build_model(cfg)
    if cfg.LOG_MODEL_INFO:
        misc.log_model_info(model)

    cu.load_test_checkpoint(cfg, model)

    # Create the testing loader.
    test_loader = loader.construct_loader(cfg, "test")
    #logger.info("Number of samples in test set: {}", len(test_loader))

    logger.info("Testing model for {} iterations".format(len(test_loader)))

    # Create the testing meter.
    test_meter = TestMeter(len(test_loader), cfg)

    perform_test(test_loader, model, test_meter, cfg)
